{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-Armed-Bandit.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H49owCzM7bPt"
      },
      "source": [
        "# Solving Multi Armed Bandit\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT_OMoQb7l2M",
        "outputId": "d676033a-2013-4dba-dd49-324e90d26b73"
      },
      "source": [
        "# Gives the agent random rewards for a limited number of steps, regardless of the agent's actions. \n",
        "import random\n",
        "\n",
        "class Environment:\n",
        "    def __init__(self):\n",
        "        self.steps_left = 100\n",
        "\n",
        "    def get_observation(self):\n",
        "        return [0.0, 0.0, 0.0]\n",
        "\n",
        "    def get_actions(self):\n",
        "        return [0, 1]\n",
        "\n",
        "    def is_done(self):\n",
        "        return self.steps_left == 0\n",
        "\n",
        "    def action(self, action):\n",
        "        if self.is_done():\n",
        "            raise Exception(\"Game is over\")\n",
        "        self.steps_left -= 1\n",
        "        return random.random()\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.total_reward = 0.0\n",
        "\n",
        "    def step(self, env):\n",
        "        current_obs = env.get_observation()\n",
        "        actions = env.get_actions()\n",
        "        reward = env.action(random.choice(actions))\n",
        "        #print(reward)\n",
        "        self.total_reward += reward\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    env = Environment()\n",
        "    agent = Agent()\n",
        "\n",
        "    while not env.is_done():\n",
        "        agent.step(env)\n",
        "\n",
        "    print(\"Total reward got: %.4f\" % agent.total_reward)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total reward got: 52.0965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u30ovSWg7u0c",
        "outputId": "7f840921-cd7a-4587-fb2e-7146d291fa30"
      },
      "source": [
        "# Phase 1\n",
        "### Extend the bandit tasks to 3 bandits\n",
        "### Rewards are as follows (bandit 1 randInt[2, 4, 6], bandit 2 randInt[4, 5, 7], bandit 3 randInt[1, 9, 11])\n",
        "### Actions will be from 1-3\n",
        "### Give the agent 100 episodes/steps \n",
        "import random\n",
        "\n",
        "class Environment:\n",
        "    def __init__(self):\n",
        "        self.steps_left = 100\n",
        "\n",
        "    def get_observation(self):\n",
        "        return [0.0, 0.0, 0.0]\n",
        "\n",
        "    def get_actions(self):\n",
        "        return [0, 1, 2]\n",
        "\n",
        "    def is_done(self):\n",
        "        return self.steps_left == 0\n",
        "\n",
        "    def action(self, action):\n",
        "        if self.is_done():\n",
        "            raise Exception(\"Game is over\")\n",
        "        self.steps_left -= 1        \n",
        "        if(action == 0):\n",
        "            return random.choice([2,4,6])\n",
        "        elif(action == 1):\n",
        "            return random.choice([4,5,7])\n",
        "        else:\n",
        "            return random.choice([1,9,11])\n",
        "            \n",
        "\n",
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.total_reward = 0.0\n",
        "\n",
        "    def step(self, env):\n",
        "        current_obs = env.get_observation()\n",
        "        actions = env.get_actions()\n",
        "        reward = env.action(random.choice(actions))\n",
        "        self.total_reward += reward\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    env = Environment()\n",
        "    agent = Agent()\n",
        "\n",
        "    while not env.is_done():\n",
        "        agent.step(env)\n",
        "    \n",
        "    print(\"Total reward got: %.4f\" % agent.total_reward)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total reward got: 536.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5-mPgOm70yN",
        "outputId": "e84b6293-d781-4338-f295-549e5539538a"
      },
      "source": [
        "#Phase 2s\n",
        "### Dilemma trying to figure out which bandit pays out more, as quickly as possible (exploration vs exploitation), without any prior knowledge.\n",
        "### Storing the average return per action observed\n",
        "### Store observations\n",
        "### Decide on an action selection strategy\n",
        "import random\n",
        "\n",
        "class Environment:\n",
        "    def __init__(self):\n",
        "        self.steps_left = 10000\n",
        "        self.observations = [0.0, 0.0, 0.0]\n",
        "        self.pulls = [0, 0, 0]\n",
        "        \n",
        "    def get_observation(self):\n",
        "        return self.observations\n",
        "\n",
        "    def get_pulls(self):\n",
        "        return self.pulls\n",
        "\n",
        "    def set_observation(self, action, reward):\n",
        "        # Incrementally computed reward averages\n",
        "        # newEstimate <- oldEstimate + 1/arm_pulls [reward - oldEstimate]        \n",
        "         stepSize = 1/self.pulls[action]\n",
        "         self.observations[action] = self.observations[action] + stepSize * (reward - self.observations[action])\n",
        "\n",
        "    def set_pulls(self, action):\n",
        "        self.pulls[action] += 1\n",
        "\n",
        "    def get_actions(self):\n",
        "        return [0, 1, 2]\n",
        "\n",
        "    def is_done(self):\n",
        "        return self.steps_left == 0\n",
        "\n",
        "    def action(self, action):\n",
        "        if self.is_done():\n",
        "            raise Exception(\"Game is over\")\n",
        "        self.steps_left -= 1\n",
        "        if(action == 0):\n",
        "            return random.choice([2,4,6])\n",
        "        elif(action == 1):\n",
        "            return random.choice([4,5,7])\n",
        "        else:\n",
        "            return random.choice([1,9,11])\n",
        "            \n",
        "\n",
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.total_reward = 0.0        \n",
        "\n",
        "    def step(self, env):\n",
        "        current_obs = env.get_observation()\n",
        "        actions = env.get_actions()\n",
        "        armSelected = random.choice(actions)\n",
        "        reward = env.action(armSelected)\n",
        "        # Update observations\n",
        "        env.set_pulls(armSelected)\n",
        "        env.set_observation(armSelected, reward)\n",
        "        self.total_reward += reward\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    env = Environment()\n",
        "    agent = Agent()\n",
        "\n",
        "    while not env.is_done():\n",
        "        agent.step(env)\n",
        "\n",
        "    print(\"Pulls\", *env.get_pulls())\n",
        "    print(\"Observations\", *env.get_observation()) \n",
        "    print(\"Total reward got: %.4f\" % agent.total_reward)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pulls 3394 3279 3327\n",
            "Observations 4.053624042427826 5.376944190301921 6.971746318004216\n",
            "Total reward got: 54584.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0F_lXhB77UO",
        "outputId": "c8328d8b-67e3-4852-97b5-4ed85940c49c"
      },
      "source": [
        "#Phase 3\n",
        "### Examine a policy - exploration vs exploitation\n",
        "### eps-greedy\n",
        "### vary the steps...what do you notice?\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class Environment:\n",
        "    def __init__(self):\n",
        "        self.steps_left = 10000\n",
        "        self.observations = [0.0, 0.0, 0.0]\n",
        "        self.pulls = [0, 0, 0]\n",
        "        \n",
        "    def get_observation(self):\n",
        "        return self.observations\n",
        "\n",
        "    def get_pulls(self):\n",
        "        return self.pulls\n",
        "\n",
        "    def set_observation(self, action, reward):\n",
        "        # Incrementally computed reward averages\n",
        "        self.observations[action] = ((self.observations[action] * self.pulls[action]-1) + reward) / self.pulls[action]\n",
        "        \n",
        "    def set_pulls(self, action):\n",
        "        self.pulls[action] += 1\n",
        "\n",
        "    def get_actions(self):\n",
        "        return [0, 1, 2]\n",
        "\n",
        "    def is_done(self):\n",
        "        return self.steps_left == 0\n",
        "\n",
        "    def action(self, action):\n",
        "        if self.is_done():\n",
        "            raise Exception(\"Game is over\")\n",
        "        self.steps_left -= 1        \n",
        "        if(action == 0):\n",
        "            return random.choice([2,4,6])\n",
        "        elif(action == 1):\n",
        "            return random.choice([4,5,7])\n",
        "        else:\n",
        "            return random.choice([1,9,11])\n",
        "            \n",
        "\n",
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.total_reward = 0.0\n",
        "        ##Epsilon greedy policy\n",
        "        self.eps = 0.15\n",
        "\n",
        "    def step(self, env):\n",
        "        current_obs = env.get_observation()\n",
        "        actions = env.get_actions()\n",
        "        ##Implement the eps greedy policy\n",
        "        rnd = random.random()\n",
        "        if(rnd > self.eps):\n",
        "            #Choose action with largest reward observed to date            \n",
        "            armSelected = np.argmax(env.get_observation())\n",
        "        else:\n",
        "            #Choose random exploratory action\n",
        "            armSelected = random.choice(actions)\n",
        "            \n",
        "        reward = env.action(armSelected)\n",
        "\n",
        "        # Update observations\n",
        "        env.set_pulls(armSelected)\n",
        "        env.set_observation(armSelected, reward)\n",
        "        self.total_reward += reward\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    env = Environment()\n",
        "    agent = Agent()\n",
        "\n",
        "    while not env.is_done():\n",
        "        agent.step(env)\n",
        "\n",
        "    print(\"Action with max avg reward\", np.argmax(env.get_observation()))\n",
        "    print(\"Pulls\", *env.get_pulls())\n",
        "    print(\"Observations\", *env.get_observation()) \n",
        "    print(\"Total reward got: %.4f\" % agent.total_reward)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action with max avg reward 2\n",
            "Pulls 531 500 8969\n",
            "Observations 17.878663765259134 27.73794246790071 62.81977981579534\n",
            "Total reward got: 68266.0000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}